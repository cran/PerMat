<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Performance Metric of fitted model</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Performance Metric of fitted model</h1>



<p><strong>Application of Performance Metrics in Predictive Modeling
</strong></p>
<div id="authors" class="section level2">
<h2>Authors</h2>
<p>Pankaj Das (<a href="https://orcid.org/0000-0003-1672-2502" class="uri">https://orcid.org/0000-0003-1672-2502</a>)</p>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Performance metrics are essential tools for evaluating the accuracy
and effectiveness of predictive models. These metrics provide
quantifiable measures to assess how well a model’s predictions match the
actual outcomes. Here are some commonly used performance metrics:</p>
<p><em>1.Mean Absolute Error(MAE):</em> It is the average distance
between Predicted and original values. Basically, it gives how we have
predicted from the actual output. However, there is one limitation
i.e. it doesn’t give any idea about the direction of the error which is
whether we are under-predicting or over-predicting our data.low MAE
values indicate that the model is correctly predicting. Larger MAE
values indicate that the model is poor at prediction.</p>
<p><em>2.Mean Squared Error(MSE):</em> It is similar to mean absolute
error but the difference is it takes the square of the average of
between predicted and original values. The main advantage to take this
metric is here, it is easier to calculate the gradient whereas, in the
case of mean absolute error, it takes complicated programming tools to
calculate the gradient. By taking the square of errors it pronounces
larger errors more than smaller errors, we can focus more on larger
errors.</p>
<p><em>3.Root Mean Square Error(RMSE):</em> We can say that RMSE is a
metric that can be obtained by just taking the square root of the MSE
value. As we know that the MSE metrics are not robust to outliers and so
are the RMSE values. This gives higher weightage to the large errors in
predictions.</p>
<p><em>4.R-squared (R²):</em> The coefficient of determination also
called the R-Square is used to evaluate the performance of a linear
regression model. It is the amount of variation in the output-dependent
attribute which is predictable from the input independent variable(s).
It is used to check how well-observed results are reproduced by the
model, depending on the ratio of total deviation of results described by
the model.</p>
<p><em>5.Accuracy</em> Model accuracy is a measure of how well a machine
learning (ML) model is able to make predictions or decisions based on
data. It is a common metric used to evaluate the performance of ML
models, and can be used to compare the performance of different models
or to assess the effectiveness of a particular model for a given
task.</p>
<p><em>6.CVRME:</em> Coefficient of variation of Root mean square is
measure of variation of the error in a prediction model, normalized by
the mean of the target variable.CVRMSE is defined as the ratio of the
root mean square error (RMSE) to the mean of the target variable,
multiplied by 100% to express it as a percentage.</p>
<p>CVRMSE=(RMSE/mean(target variable))*100 %</p>
<p>CVRMSE measures the average distance between predicted values and the
true values and thus reflects the accuracy of the model. CVRMSE reflects
the relative size of errors in the model, compared to the scale of the
target variable. CVRMSE is useful metric when target variable has a
large scale of the target variable has a large scale or a wide range of
values , as it provides a standardized measure of model’s performance. A
lower CVRMSE indicates a more accurate and reliable model, while a
higher CVRMSE indicates a less accurate and more variable model. CVRMSE
values can be used in combination with other metrics, such as R-Squared
and Mean absolute error (MAE), to provide a comprehensive evaluation of
the model’s performance.</p>
<p><em>7.NRMSE:</em> Normalized root mean square error is a measure of
the accuracy of a prediction model, representing the ratio of the root
mean squared error to the range of the dependent variable.It is used to
compare the performance of different models or to evaluate the accuracy
of a model over time. The formula of NRMSE is</p>
<p>NRMSE= RMSE/ (Y_max - Y_min)</p>
<p>where Y_max is maximum value of target variable Y_min is minimum
value of target variable</p>
<p>NRMSE values range from 0 to 1 with lower values indicating better
model accuracy.The values can be used to compare the performance of
different regression models or to track the performance of the same
model over time.</p>
<p><em>8.MAPE:</em> Mean Absolute Percentage Error (MAPE) is a metric
used to measure the accuracy of a predictive model. It represents the
average of the absolute percentage errors between the actual values and
the predicted values.MAPE is expressed as a percentage, making it easy
to interpret. It indicates the average percentage error made by the
model in its predictions. Lower MAPE values represent better predictive
accuracy.</p>
<p><em>ME:</em> Mean Error (ME) is a metric that measures the average
difference between the actual values and the predicted values. Unlike
other metrics that only consider the magnitude of errors, ME retains the
sign of the errors, indicating whether predictions are generally over or
under the actual values. ME can be positive or negative. A positive ME
indicates that, on average, the model’s predictions are lower than the
actual values (underestimation). A negative ME indicates that, on
average, the model’s predictions are higher than the actual values
(overestimation). An ME close to zero indicates that the model does not
have a significant bias in either direction.</p>
</div>
<div id="functions-in-the-r-package" class="section level2">
<h2>Functions in the R package</h2>
<p><strong>RMSE(actual, predicted):</strong> It help in RMSE calculation
of the fitted model</p>
<p><strong>NRMSE(actual, predicted):</strong> It help inNRMSE
calculation of the fitted model.</p>
<p><strong>CVRMSE(actual, predicted):</strong> It help in CVRMSE
calculation of the fitted model.</p>
<p><strong>R2(actual, predicted):</strong> It help in RSquare
calculation of the fitted model.</p>
<p><strong>accuracy(actual, predicted):</strong> It help in Accuracy
calculation of the fitted model.</p>
<p><strong>ME(actual, predicted):</strong> It help inMaximum error
calculation of the fitted model.</p>
<p><strong>MAPE(actual, predicted):</strong> It help in MAPE calculation
of the fitted model.</p>
<p><strong>MAE(actual, predicted):</strong> It help in MAE calculation
of the fitted model.</p>
</div>
<div id="uses-of-the-performance-metrics" class="section level2">
<h2>Uses of the Performance Metrics</h2>
<p><strong>1.Model Evaluation:</strong> Purpose: Metrics such as MAE,
MSE, RMSE, and R² help evaluate how well a predictive model
performs.</p>
<p>Application: By comparing these metrics across different models, data
scientists can determine which model provides the best fit for the
data.</p>
<p><strong>2.Model Selection:</strong> Purpose: Performance metrics
guide the selection of the most appropriate model for a given
problem.</p>
<p>Application: When multiple models are developed, metrics are used to
select the model that minimizes error and maximizes explained
variance.</p>
<p><strong>3.Model Tuning:</strong> Purpose: Metrics assist in
hyperparameter tuning to improve model performance.</p>
<p>Application: During processes like cross-validation, performance
metrics are used to adjust model parameters to achieve optimal
performance.</p>
<p><strong>4.Benchmarking:</strong> Purpose: Metrics provide benchmarks
to compare current models against new or alternative models.</p>
<p>Application: Metrics allow for tracking performance improvements over
time or comparing against industry standards.</p>
<p><strong>5.Error Analysis:</strong> Purpose: Identifying the type and
magnitude of prediction errors helps in understanding model
limitations.</p>
<p>Application: Metrics like MSE and RMSE highlight large errors, while
MAE indicates average error, guiding further investigation and
refinement.</p>
<p><strong>6.Decision Making:</strong> Purpose: Performance metrics
inform business and operational decisions based on model
predictions.</p>
<p>Application: Metrics help stakeholders understand the reliability of
predictions, influencing strategic decisions in areas like finance,
healthcare, marketing, and more.</p>
<p><strong>7.Model Reporting:</strong> Purpose: Clear communication of
model performance to stakeholders.</p>
<p>Application: Metrics provide quantitative evidence of model
effectiveness, useful for reports, presentations, and documentation.</p>
<p><strong>8.Algorithm Comparison:</strong> Purpose: Metrics facilitate
comparison between different types of algorithms (e.g., linear
regression vs. decision trees).</p>
<p>Application: By evaluating metrics, one can determine which algorithm
better suits the data characteristics and problem requirements.</p>
<p><strong>9.Ensuring Model Robustness:</strong> Purpose: To ensure that
a model performs well on unseen data.</p>
<p>Application: Metrics help in validating the robustness and
generalizability of the model by comparing performance on training and
test datasets.</p>
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<p><em>Das, P., Jha, G. K., Lama, A., Parsad, R. and Mishra, D. (2020).
Empirical Mode Decomposition based Support Vector Regression for
Agricultural Price Forecasting. Indian Journal of Extension Education,
56(2):7-12.(<a href="http://krishi.icar.gov.in/jspui/handle/123456789/44138" class="uri">http://krishi.icar.gov.in/jspui/handle/123456789/44138</a>).</em></p>
<p><em>Bharti, Das,P.,Banerjee, R., Ahmad, T., Devi, S. and Verma G.
(2023).Machine-LearningBased Apple Yield Prediction using Morphological
Characters. Horticulturae. 9, (4),
436.https://doi.org/10.3390/horticulturae9040436 </em></p>
<p><em>Das,P., Jha, G. K., Lama, A.and Parsad, R.(2023). Crop Yield
Prediction using Hybrid Machine Learning approach: A Case study of
Lentil (Lens culinaris Medik.) Agriculture, 13 (3), 596. <a href="https://doi.org/10.3390/agriculture13030596" class="uri">https://doi.org/10.3390/agriculture13030596</a> </em></p>
<p><em>Das, P. Jha, G. K. and Lama, A. (2023). Empirical Mode
Decomposition Based Ensemble Hybrid Machine Learning Models for
Agricultural Commodity Price Forecasting. Statistics and Applications,
21(1),99-112.(<a href="http://krishi.icar.gov.in/jspui/handle/123456789/77772" class="uri">http://krishi.icar.gov.in/jspui/handle/123456789/77772</a>).</em></p>
<p><em>Das, P., Jha, G. K., Lama, A. and Bharti (2022). EMD-SVR Hybrid
Machine Learning Model and its Application in Agricultural Price
Forecasting. Bhartiya Krishi Anusandhan Patrika. (DOI:
10.18805/BKAP385)</em></p>
<p><em>Das, P. (2019). Study On Machine Learning Techniques Based Hybrid
Model for Forecasting in Agriculture. Published Ph.D. Thesis.</em></p>
<p><em>Choudhury, K., Jha, G. K., Das, P. and Chaturvedi, K. K. (2019).
Forecasting Potato Price using Ensemble Artificial Neural Networks.
Indian Journal of Extension Education, 55(1):71-77.(<a href="http://krishi.icar.gov.in/jspui/handle/123456789/44873" class="uri">http://krishi.icar.gov.in/jspui/handle/123456789/44873</a>).</em></p>
<p><em>Das, P., Lama, A. and Jha, G. K. (2022). Variational Mode
Decomposition based Machine Learning Models Optimized with Genetic
Algorithm for Price Forecasting. Journal of the Indian Society of
Agricultural Statistics, 76(3), 141-150. (<a href="http://krishi.icar.gov.in/jspui/handle/123456789/76648" class="uri">http://krishi.icar.gov.in/jspui/handle/123456789/76648</a>)</em></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(PerMat)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="do">##Example how the package works</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#Dataset generation</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>actual <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>, <span class="dv">300</span>, <span class="dv">350</span>, <span class="dv">400</span>, <span class="dv">450</span>, <span class="dv">500</span>, <span class="dv">550</span>)</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">95</span>, <span class="dv">148</span>, <span class="dv">210</span>, <span class="dv">245</span>, <span class="dv">290</span>, <span class="dv">360</span>, <span class="dv">395</span>, <span class="dv">440</span>, <span class="dv">510</span>, <span class="dv">540</span>)</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">#RMSE calculation of the fitted model</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="fu">RMSE</span>(actual, predicted)</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co">#&gt; Mean Squared Error: 67.9</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co">#&gt; Root Mean Squared Error: 8.24014562978107</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co">#NRMSE calculation of the fitted model</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="fu">NRMSE</span>(actual, predicted)</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="co">#&gt; Normalised Root Mean Squared Error:0.0183114347328468</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co">#CVRMSE calculation of the fitted model</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a><span class="fu">CVRMSE</span>(actual, predicted)</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a><span class="co">#&gt; Coefficient of Variation of Root Mean Squared Error:0.0253542942454802</span></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a><span class="co">#&gt; Coefficient of Variation of Root Mean Squared Error (In percentage):2.53542942454802</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a><span class="co">#RSquare calculation of the fitted model</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a><span class="fu">R2</span>(actual, predicted)</span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a><span class="co">#&gt; Coefficient of Determination (R-Square):0.996851326601227</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a><span class="co">#&gt; Percentage of Variation Expressed by The Model:99.6851326601227</span></span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a><span class="co">#Maximum error calculation of the fitted model</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a><span class="fu">ME</span>(actual, predicted)</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a><span class="co">#&gt; Maximum Error: 10</span></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a><span class="co">#MAPE calculation of the fitted model</span></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a><span class="fu">MAPE</span>(actual, predicted)</span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a><span class="co">#&gt; Mean Absolute Percentage Error: 0.0268142135642136</span></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a><span class="co">#&gt; Mean Absolute Percentage Error (In percentage): 2.68142135642136</span></span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a><span class="co">#MAE calculation of the fitted model</span></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a><span class="fu">MAE</span>(actual, predicted)</span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a><span class="co">#&gt; Mean Absolute Error: 7.7</span></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a><span class="co">#Accuracy calculation of the fitted model</span></span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a><span class="fu">accuracy</span>(actual, predicted)</span>
<span id="cb1-47"><a href="#cb1-47" tabindex="-1"></a><span class="co">#&gt; Accuracy of Model: 0.992900072150072</span></span></code></pre></div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
